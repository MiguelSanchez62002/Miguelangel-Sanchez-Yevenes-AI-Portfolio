{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0173ac91",
      "metadata": {
        "id": "0173ac91"
      },
      "source": [
        "\n",
        "# ITAI 2373 Module 05: Part-of-Speech Tagging\n",
        "## In-Class Exercise & Homework Lab\n",
        "\n",
        "Welcome to the world of Part-of-Speech (POS) tagging - the \"grammar police\" of Natural Language Processing! 🚔📝\n",
        "\n",
        "In this notebook, you'll explore how computers understand the grammatical roles of words in sentences, from simple rule-based approaches to modern AI systems.\n",
        "\n",
        "### What You'll Learn:\n",
        "- **Understand POS tagging fundamentals** and why it matters in daily apps\n",
        "- **Use NLTK and SpaCy** for practical text analysis\n",
        "- **Navigate different tag sets** and understand their trade-offs\n",
        "- **Handle real-world messy text** like speech transcripts and social media\n",
        "- **Apply POS tagging** to solve actual business problems\n",
        "\n",
        "### Structure:\n",
        "- **Part 1**: In-Class Exercise (30-45 minutes) - Basic concepts and hands-on practice\n",
        "- **Part 2**: Homework Lab - Real-world applications and advanced challenges\n",
        "\n",
        "---\n",
        "\n",
        "*💡 **Pro Tip**: POS tagging is everywhere! It helps search engines understand \"Apple stock\" vs \"apple pie\", helps Siri understand your commands, and powers autocorrect on your phone.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35d96f92",
      "metadata": {
        "id": "35d96f92"
      },
      "source": [
        "\n",
        "## 🛠️ Setup and Installation\n",
        "\n",
        "Let's get our tools ready! We'll use two powerful libraries:\n",
        "- **NLTK**: The \"Swiss Army knife\" of NLP - comprehensive but requires setup\n",
        "- **SpaCy**: The \"speed demon\" - built for production, cleaner output\n",
        "\n",
        "Run the cells below to install and set up everything we need.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a5f81ea",
      "metadata": {
        "id": "2a5f81ea"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Install required libraries (run this first!)\n",
        "!pip install nltk spacy matplotlib seaborn pandas\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "print(\"✅ Installation complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1135905",
      "metadata": {
        "id": "a1135905"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Import all the libraries we'll need\n",
        "import nltk\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Download NLTK data (this might take a moment)\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')\n",
        "\n",
        "# Load SpaCy model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "print(\"🎉 All libraries loaded successfully!\")\n",
        "print(\"📚 NLTK version:\", nltk.__version__)\n",
        "print(\"🚀 SpaCy version:\", spacy.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c816a7ce",
      "metadata": {
        "id": "c816a7ce"
      },
      "source": [
        "\n",
        "---\n",
        "# 🎯 PART 1: IN-CLASS EXERCISE (30-45 minutes)\n",
        "\n",
        "Welcome to the hands-on portion! We'll start with the basics and build up your understanding step by step.\n",
        "\n",
        "## Learning Goals for Part 1:\n",
        "1. Understand what POS tagging does\n",
        "2. Use NLTK and SpaCy for basic tagging\n",
        "3. Interpret and compare different tag outputs\n",
        "4. Explore word ambiguity with real examples\n",
        "5. Compare different tagging approaches\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76538fce",
      "metadata": {
        "id": "76538fce"
      },
      "source": [
        "\n",
        "## 🔍 Activity 1: Your First POS Tags (10 minutes)\n",
        "\n",
        "Let's start with the classic example: \"The quick brown fox jumps over the lazy dog\"\n",
        "\n",
        "This sentence contains most common parts of speech, making it perfect for learning!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d12c1b4",
      "metadata": {
        "id": "6d12c1b4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Let's start with a classic example\n",
        "sentence = \"The quick brown fox jumps over the lazy dog\"\n",
        "\n",
        "# TODO: Use NLTK to tokenize and tag the sentence\n",
        "# Hint: Use nltk.word_tokenize() and nltk.pos_tag()\n",
        "tokens = # YOUR CODE HERE\n",
        "pos_tags = # YOUR CODE HERE\n",
        "\n",
        "print(\"Original sentence:\", sentence)\n",
        "print(\"\\nTokens:\", tokens)\n",
        "print(\"\\nPOS Tags:\")\n",
        "for word, tag in pos_tags:\n",
        "    print(f\"  {word:8} -> {tag}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "555b5f5d",
      "metadata": {
        "id": "555b5f5d"
      },
      "source": [
        "\n",
        "### 🤔 Quick Questions:\n",
        "1. What does 'DT' mean? What about 'JJ'?\n",
        "2. Why do you think 'brown' and 'lazy' have the same tag?\n",
        "3. Can you guess what 'VBZ' represents?\n",
        "\n",
        "*Hint: Think about the grammatical role each word plays in the sentence!*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3045611",
      "metadata": {
        "id": "f3045611"
      },
      "source": [
        "\n",
        "## 🚀 Activity 2: SpaCy vs NLTK Showdown (10 minutes)\n",
        "\n",
        "Now let's see how SpaCy handles the same sentence. SpaCy uses cleaner, more intuitive tag names.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9669b15",
      "metadata": {
        "id": "a9669b15"
      },
      "outputs": [],
      "source": [
        "\n",
        "# TODO: Process the same sentence with SpaCy\n",
        "# Hint: Use nlp(sentence) and access .text and .pos_ attributes\n",
        "doc = # YOUR CODE HERE\n",
        "\n",
        "print(\"SpaCy POS Tags:\")\n",
        "for token in doc:\n",
        "    print(f\"  {token.text:8} -> {token.pos_:6} ({token.tag_})\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"COMPARISON:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Let's compare side by side\n",
        "nltk_tags = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
        "spacy_doc = nlp(sentence)\n",
        "\n",
        "print(f\"{'Word':10} {'NLTK':8} {'SpaCy':10}\")\n",
        "print(\"-\" * 30)\n",
        "for i, (word, nltk_tag) in enumerate(nltk_tags):\n",
        "    spacy_tag = spacy_doc[i].pos_\n",
        "    print(f\"{word:10} {nltk_tag:8} {spacy_tag:10}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "889c2fcc",
      "metadata": {
        "id": "889c2fcc"
      },
      "source": [
        "\n",
        "### 🎯 Discussion Points:\n",
        "- Which tags are easier to understand: NLTK's or SpaCy's?\n",
        "- Do you notice any differences in how they tag the same words?\n",
        "- Which system would you prefer for a beginner? Why?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d773576",
      "metadata": {
        "id": "1d773576"
      },
      "source": [
        "\n",
        "## 🎭 Activity 3: The Ambiguity Challenge (15 minutes)\n",
        "\n",
        "Here's where things get interesting! Many words can be different parts of speech depending on context. Let's explore this with some tricky examples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4de9076f",
      "metadata": {
        "id": "4de9076f"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Ambiguous words in different contexts\n",
        "ambiguous_sentences = [\n",
        "    \"I will lead the team to victory.\",           # lead = verb\n",
        "    \"The lead pipe is heavy.\",                    # lead = noun (metal)\n",
        "    \"She took the lead in the race.\",            # lead = noun (position)\n",
        "    \"The bank approved my loan.\",                # bank = noun (financial)\n",
        "    \"We sat by the river bank.\",                 # bank = noun (shore)\n",
        "    \"I bank with Chase.\",                        # bank = verb\n",
        "]\n",
        "\n",
        "print(\"🎭 AMBIGUITY EXPLORATION\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "for sentence in ambiguous_sentences:\n",
        "    print(f\"\\nSentence: {sentence}\")\n",
        "\n",
        "    # TODO: Tag each sentence and find the ambiguous word\n",
        "    # Focus on 'lead' and 'bank' - what tags do they get?\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    tags = nltk.pos_tag(tokens)\n",
        "\n",
        "    # Find and highlight the key word\n",
        "    for word, tag in tags:\n",
        "        if word.lower() in ['lead', 'bank']:\n",
        "            print(f\"  🎯 '{word}' is tagged as: {tag}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b299cc67",
      "metadata": {
        "id": "b299cc67"
      },
      "source": [
        "\n",
        "### 🧠 Think About It:\n",
        "1. How does the computer know the difference between \"lead\" (metal) and \"lead\" (guide)?\n",
        "2. What clues in the sentence help determine the correct part of speech?\n",
        "3. Can you think of other words that change meaning based on context?\n",
        "\n",
        "**Try This**: Add your own ambiguous sentences to the list above and see how the tagger handles them!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd61b43a",
      "metadata": {
        "id": "cd61b43a"
      },
      "source": [
        "\n",
        "## 📊 Activity 4: Tag Set Showdown (10 minutes)\n",
        "\n",
        "NLTK can use different tag sets. Let's compare the detailed Penn Treebank tags (~45 tags) with the simpler Universal Dependencies tags (~17 tags).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fd01009",
      "metadata": {
        "id": "9fd01009"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Compare different tag sets\n",
        "test_sentence = \"The brilliant students quickly solved the challenging programming assignment.\"\n",
        "\n",
        "# TODO: Get tags using both Penn Treebank and Universal tagsets\n",
        "# Hint: Use tagset='universal' parameter for universal tags\n",
        "penn_tags = # YOUR CODE HERE\n",
        "universal_tags = # YOUR CODE HERE\n",
        "\n",
        "print(\"TAG SET COMPARISON\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"{'Word':15} {'Penn Treebank':15} {'Universal':10}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# TODO: Print comparison table\n",
        "# Hint: Zip the two tag lists together\n",
        "for # YOUR CODE HERE:\n",
        "    print(f\"{word:15} {penn_tag:15} {univ_tag:10}\")\n",
        "\n",
        "# Let's also visualize the tag distribution\n",
        "penn_tag_counts = Counter([tag for word, tag in penn_tags])\n",
        "univ_tag_counts = Counter([tag for word, tag in universal_tags])\n",
        "\n",
        "print(f\"\\n📊 Penn Treebank uses {len(penn_tag_counts)} different tags\")\n",
        "print(f\"📊 Universal uses {len(univ_tag_counts)} different tags\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fab1efe",
      "metadata": {
        "id": "2fab1efe"
      },
      "source": [
        "\n",
        "### 🤔 Reflection Questions:\n",
        "1. Which tag set is more detailed? Which is simpler? Enter your answer below\n",
        "\n",
        "2. When might you want detailed tags vs. simple tags? Enter your answer below\n",
        "\n",
        "3. If you were building a search engine, which would you choose? Why? Enter your answer below\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2e2ce7d",
      "metadata": {
        "id": "e2e2ce7d"
      },
      "source": [
        "\n",
        "---\n",
        "# 🎓 End of Part 1: In-Class Exercise\n",
        "\n",
        "Great work! You've learned the fundamentals of POS tagging and gotten hands-on experience with both NLTK and SpaCy.\n",
        "\n",
        "## What You've Accomplished:\n",
        "✅ Used NLTK and SpaCy for basic POS tagging  \n",
        "✅ Interpreted different tag systems  \n",
        "✅ Explored word ambiguity and context  \n",
        "✅ Compared different tagging approaches  \n",
        "\n",
        "## 🏠 Ready for Part 2?\n",
        "The homework lab will challenge you with real-world applications, messy data, and advanced techniques. You'll analyze customer service transcripts, handle informal language, and benchmark different taggers.\n",
        "\n",
        "**Take a break, then dive into Part 2 when you're ready!**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "571e9ac8",
      "metadata": {
        "id": "571e9ac8"
      },
      "source": [
        "\n",
        "# 🏠 PART 2: HOMEWORK LAB\n",
        "## Real-World POS Tagging Challenges\n",
        "\n",
        "Welcome to the advanced section! Here you'll tackle the messy, complex world of real text data. This is where POS tagging gets interesting (and challenging)!\n",
        "\n",
        "## Learning Goals for Part 2:\n",
        "1. Process real-world, messy text data\n",
        "2. Handle speech transcripts and informal language\n",
        "3. Analyze customer service scenarios\n",
        "4. Benchmark and compare different taggers\n",
        "5. Understand limitations and edge cases\n",
        "\n",
        "## 📋 Submission Requirements:\n",
        "- Complete all exercises with working code\n",
        "- Answer all reflection questions\n",
        "- Include at least one visualization\n",
        "- Submit your completed notebook file\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15ae7ff1",
      "metadata": {
        "id": "15ae7ff1"
      },
      "source": [
        "\n",
        "## 🌍 Lab Exercise 1: Messy Text Challenge (25 minutes)\n",
        "\n",
        "Real-world text is nothing like textbook examples! Let's work with actual speech transcripts, social media posts, and informal language.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cacc5fe7",
      "metadata": {
        "id": "cacc5fe7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Real-world messy text samples\n",
        "messy_texts = [\n",
        "    # Speech transcript with disfluencies\n",
        "    \"Um, so like, I was gonna say that, uh, the system ain't working right, you know?\",\n",
        "\n",
        "    # Social media style\n",
        "    \"OMG this app is sooo buggy rn 😤 cant even login smh\",\n",
        "\n",
        "    # Customer service transcript\n",
        "    \"Yeah hi um I'm calling because my internet's been down since like yesterday and I've tried unplugging the router thingy but it's still not working\",\n",
        "\n",
        "    # Informal contractions and slang\n",
        "    \"Y'all better fix this ASAP cuz I'm bout to switch providers fr fr\",\n",
        "\n",
        "    # Technical jargon mixed with casual speech\n",
        "    \"The API endpoint is returning a 500 error but idk why it's happening tbh\"\n",
        "]\n",
        "\n",
        "print(\"🔍 PROCESSING MESSY TEXT\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# TODO: Process each messy text sample\n",
        "# 1. Use both NLTK and SpaCy\n",
        "# 2. Count how many words each tagger fails to recognize properly\n",
        "# 3. Identify problematic words (slang, contractions, etc.)\n",
        "\n",
        "for i, text in enumerate(messy_texts, 1):\n",
        "    print(f\"\\n📝 Sample {i}: {text}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # NLTK processing\n",
        "    nltk_tokens = nltk.word_tokenize(text)\n",
        "    nltk_tags = nltk.pos_tag(nltk_tokens)\n",
        "\n",
        "    # TODO: SpaCy processing\n",
        "    spacy_doc = # YOUR CODE HERE\n",
        "\n",
        "    # TODO: Find problematic words (tagged as 'X' or unknown)\n",
        "    problematic_nltk = # YOUR CODE HERE\n",
        "    problematic_spacy = # YOUR CODE HERE\n",
        "\n",
        "    print(f\"NLTK problematic words: {problematic_nltk}\")\n",
        "    print(f\"SpaCy problematic words: {problematic_spacy}\")\n",
        "\n",
        "    # TODO: Calculate success rate\n",
        "    nltk_success_rate = # YOUR CODE HERE\n",
        "    spacy_success_rate = # YOUR CODE HERE\n",
        "\n",
        "    print(f\"NLTK success rate: {nltk_success_rate:.1%}\")\n",
        "    print(f\"SpaCy success rate: {spacy_success_rate:.1%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35a387a8",
      "metadata": {
        "id": "35a387a8"
      },
      "source": [
        "\n",
        "### 🎯 Analysis Questions:\n",
        "1. Which tagger handles informal language better?\n",
        "2. What types of words cause the most problems?\n",
        "3. How might you preprocess text to improve tagging accuracy?\n",
        "4. What are the implications for real-world applications?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "966c3a77",
      "metadata": {
        "id": "966c3a77"
      },
      "source": [
        "\n",
        "## 📞 Lab Exercise 2: Customer Service Analysis Case Study (30 minutes)\n",
        "\n",
        "You're working for a tech company that receives thousands of customer service calls daily. Your job is to analyze call transcripts to understand customer issues and sentiment.\n",
        "\n",
        "**Business Goal**: Automatically categorize customer problems and identify emotional language.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7a5ed54",
      "metadata": {
        "id": "c7a5ed54"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Simulated customer service call transcripts\n",
        "customer_transcripts = [\n",
        "    {\n",
        "        'id': 'CALL_001',\n",
        "        'transcript': \"Hi, I'm really frustrated because my account got locked and I can't access my files. I've been trying for hours and nothing works. This is completely unacceptable.\",\n",
        "        'category': 'account_access'\n",
        "    },\n",
        "    {\n",
        "        'id': 'CALL_002',\n",
        "        'transcript': \"Hello, I love your service but I'm having a small issue with the mobile app. It crashes whenever I try to upload photos. Could you please help me fix this?\",\n",
        "        'category': 'technical_issue'\n",
        "    },\n",
        "    {\n",
        "        'id': 'CALL_003',\n",
        "        'transcript': \"Your billing system charged me twice this month! I want a refund immediately. This is ridiculous and I'm considering canceling my subscription.\",\n",
        "        'category': 'billing'\n",
        "    },\n",
        "    {\n",
        "        'id': 'CALL_004',\n",
        "        'transcript': \"I'm confused about how to use the new features you added. The interface changed and I can't find anything. Can someone walk me through it?\",\n",
        "        'category': 'user_guidance'\n",
        "    }\n",
        "]\n",
        "\n",
        "# TODO: Analyze each transcript for:\n",
        "# 1. Emotional language (adjectives that indicate sentiment)\n",
        "# 2. Action words (verbs that indicate what customer wants)\n",
        "# 3. Problem indicators (nouns related to issues)\n",
        "\n",
        "analysis_results = []\n",
        "\n",
        "for call in customer_transcripts:\n",
        "    print(f\"\\n🎧 Analyzing {call['id']}\")\n",
        "    print(f\"Category: {call['category']}\")\n",
        "    print(f\"Transcript: {call['transcript']}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # TODO: Process with SpaCy (it's better for this task)\n",
        "    doc = # YOUR CODE HERE\n",
        "\n",
        "    # TODO: Extract different types of words\n",
        "    emotional_adjectives = # YOUR CODE HERE (JJ tags, emotional words)\n",
        "    action_verbs = # YOUR CODE HERE (VB* tags)\n",
        "    problem_nouns = # YOUR CODE HERE (NN* tags related to problems)\n",
        "\n",
        "    # TODO: Calculate sentiment indicators\n",
        "    positive_words = # YOUR CODE HERE (love, great, good, etc.)\n",
        "    negative_words = # YOUR CODE HERE (frustrated, ridiculous, unacceptable, etc.)\n",
        "\n",
        "    result = {\n",
        "        'call_id': call['id'],\n",
        "        'category': call['category'],\n",
        "        'emotional_adjectives': emotional_adjectives,\n",
        "        'action_verbs': action_verbs,\n",
        "        'problem_nouns': problem_nouns,\n",
        "        'sentiment_score': len(positive_words) - len(negative_words),\n",
        "        'urgency_indicators': # TODO: Count urgent words (immediately, ASAP, etc.)\n",
        "    }\n",
        "\n",
        "    analysis_results.append(result)\n",
        "\n",
        "    print(f\"Emotional adjectives: {emotional_adjectives}\")\n",
        "    print(f\"Action verbs: {action_verbs}\")\n",
        "    print(f\"Problem nouns: {problem_nouns}\")\n",
        "    print(f\"Sentiment score: {result['sentiment_score']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6db420ac",
      "metadata": {
        "id": "6db420ac"
      },
      "outputs": [],
      "source": [
        "\n",
        "# TODO: Create a summary visualization\n",
        "# Hint: Use matplotlib or seaborn to create charts\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Convert results to DataFrame for easier analysis\n",
        "df = pd.DataFrame(analysis_results)\n",
        "\n",
        "# TODO: Create visualizations\n",
        "# 1. Sentiment scores by category\n",
        "# 2. Most common emotional adjectives\n",
        "# 3. Action verbs frequency\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# TODO: Plot 1 - Sentiment by category\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Plot 2 - Word frequency analysis\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Plot 3 - Problem categorization\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Plot 4 - Urgency analysis\n",
        "# YOUR CODE HERE\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c9a271c",
      "metadata": {
        "id": "8c9a271c"
      },
      "source": [
        "\n",
        "### 💼 Business Impact Questions:\n",
        "1. How could this analysis help prioritize customer service tickets?\n",
        "2. What patterns do you notice in different problem categories?\n",
        "3. How might you automate the routing of calls based on POS analysis?\n",
        "4. What are the limitations of this approach?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22733d79",
      "metadata": {
        "id": "22733d79"
      },
      "source": [
        "\n",
        "## ⚡ Lab Exercise 3: Tagger Performance Benchmarking (20 minutes)\n",
        "\n",
        "Let's scientifically compare different POS taggers on various types of text. This will help you understand when to use which tool.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39ac25fc",
      "metadata": {
        "id": "39ac25fc"
      },
      "outputs": [],
      "source": [
        "\n",
        "import time\n",
        "from collections import defaultdict\n",
        "\n",
        "# Different text types for testing\n",
        "test_texts = {\n",
        "    'formal': \"The research methodology employed in this study follows established academic protocols.\",\n",
        "    'informal': \"lol this study is kinda weird but whatever works i guess 🤷‍♀️\",\n",
        "    'technical': \"The API returns a JSON response with HTTP status code 200 upon successful authentication.\",\n",
        "    'conversational': \"So like, when you click that button thingy, it should totally work, right?\",\n",
        "    'mixed': \"OMG the algorithm's performance is absolutely terrible! The accuracy dropped to 23% wtf\"\n",
        "}\n",
        "\n",
        "# TODO: Benchmark different taggers\n",
        "# Test: NLTK Penn Treebank, NLTK Universal, SpaCy\n",
        "# Metrics: Speed, tag consistency, handling of unknown words\n",
        "\n",
        "benchmark_results = defaultdict(list)\n",
        "\n",
        "for text_type, text in test_texts.items():\n",
        "    print(f\"\\n🧪 Testing {text_type.upper()} text:\")\n",
        "    print(f\"Text: {text}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # TODO: NLTK Penn Treebank timing\n",
        "    start_time = time.time()\n",
        "    # YOUR CODE HERE\n",
        "    nltk_penn_time = time.time() - start_time\n",
        "\n",
        "    # TODO: NLTK Universal timing\n",
        "    start_time = time.time()\n",
        "    # YOUR CODE HERE\n",
        "    nltk_univ_time = time.time() - start_time\n",
        "\n",
        "    # TODO: SpaCy timing\n",
        "    start_time = time.time()\n",
        "    # YOUR CODE HERE\n",
        "    spacy_time = time.time() - start_time\n",
        "\n",
        "    # TODO: Count unknown/problematic tags\n",
        "    nltk_unknown = # YOUR CODE HERE\n",
        "    spacy_unknown = # YOUR CODE HERE\n",
        "\n",
        "    # Store results\n",
        "    benchmark_results[text_type] = {\n",
        "        'nltk_penn_time': nltk_penn_time,\n",
        "        'nltk_univ_time': nltk_univ_time,\n",
        "        'spacy_time': spacy_time,\n",
        "        'nltk_unknown': nltk_unknown,\n",
        "        'spacy_unknown': spacy_unknown\n",
        "    }\n",
        "\n",
        "    print(f\"NLTK Penn time: {nltk_penn_time:.4f}s\")\n",
        "    print(f\"NLTK Univ time: {nltk_univ_time:.4f}s\")\n",
        "    print(f\"SpaCy time: {spacy_time:.4f}s\")\n",
        "    print(f\"NLTK unknown words: {nltk_unknown}\")\n",
        "    print(f\"SpaCy unknown words: {spacy_unknown}\")\n",
        "\n",
        "# TODO: Create performance comparison visualization\n",
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a656d62d",
      "metadata": {
        "id": "a656d62d"
      },
      "source": [
        "\n",
        "### 📊 Performance Analysis:\n",
        "1. Which tagger is fastest? Does speed matter for your use case?\n",
        "2. Which handles informal text best?\n",
        "3. How do the taggers compare on technical jargon?\n",
        "4. What trade-offs do you see between speed and accuracy?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08244956",
      "metadata": {
        "id": "08244956"
      },
      "source": [
        "\n",
        "## 🚨 Lab Exercise 4: Edge Cases and Error Analysis (15 minutes)\n",
        "\n",
        "Every system has limitations. Let's explore the edge cases where POS taggers struggle and understand why.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5e4119e",
      "metadata": {
        "id": "b5e4119e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Challenging edge cases\n",
        "edge_cases = [\n",
        "    \"Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo.\",  # Famous ambiguous sentence\n",
        "    \"Time flies like an arrow; fruit flies like a banana.\",              # Classic ambiguity\n",
        "    \"The man the boat the river.\",                                       # Garden path sentence\n",
        "    \"Police police Police police police police Police police.\",          # Recursive structure\n",
        "    \"James while John had had had had had had had had had had had a better effect on the teacher.\",  # Had had had...\n",
        "    \"Can can can can can can can can can can.\",                         # Modal/noun ambiguity\n",
        "    \"@username #hashtag http://bit.ly/abc123 😂🔥💯\",                   # Social media elements\n",
        "    \"COVID-19 AI/ML IoT APIs RESTful microservices\",                    # Modern technical terms\n",
        "]\n",
        "\n",
        "print(\"🚨 EDGE CASE ANALYSIS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# TODO: Process each edge case and analyze failures\n",
        "for i, text in enumerate(edge_cases, 1):\n",
        "    print(f\"\\n🔍 Edge Case {i}:\")\n",
        "    print(f\"Text: {text}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    try:\n",
        "        # TODO: Process with both taggers\n",
        "        nltk_tags = # YOUR CODE HERE\n",
        "        spacy_doc = # YOUR CODE HERE\n",
        "\n",
        "        # TODO: Identify potential errors or weird tags\n",
        "        # Look for: repeated tags, unusual patterns, X tags, etc.\n",
        "\n",
        "        print(\"NLTK tags:\", [(w, t) for w, t in nltk_tags])\n",
        "        print(\"SpaCy tags:\", [(token.text, token.pos_) for token in spacy_doc])\n",
        "\n",
        "        # TODO: Analyze what went wrong\n",
        "        # YOUR ANALYSIS CODE HERE\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error processing: {e}\")\n",
        "\n",
        "# TODO: Reflection on limitations\n",
        "print(\"\\n🤔 REFLECTION ON LIMITATIONS:\")\n",
        "print(\"=\" * 40)\n",
        "# YOUR REFLECTION CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "969fe260",
      "metadata": {
        "id": "969fe260"
      },
      "source": [
        "\n",
        "### 🧠 Critical Thinking Questions:\n",
        "Enter you asnwers below each question.\n",
        "1. Why do these edge cases break the taggers?\n",
        "\n",
        "2. How might you preprocess text to handle some of these issues?\n",
        "\n",
        "3. When would these limitations matter in real applications?\n",
        "\n",
        "4. How do modern large language models handle these cases differently?\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4aa06861",
      "metadata": {
        "id": "4aa06861"
      },
      "source": [
        "\n",
        "## 🎯 Final Reflection and Submission\n",
        "\n",
        "Congratulations! You've completed a comprehensive exploration of POS tagging, from basic concepts to real-world challenges.\n",
        "\n",
        "### 📝 Reflection Questions (Answer in the cell below):\n",
        "\n",
        "1. **Tool Comparison**: Based on your experience, when would you choose NLTK vs SpaCy? Consider factors like ease of use, accuracy, speed, and application type.\n",
        "\n",
        "2. **Real-World Applications**: Describe a specific business problem where POS tagging would be valuable. How would you implement it?\n",
        "\n",
        "3. **Limitations and Solutions**: What are the biggest limitations you discovered? How might you work around them?\n",
        "\n",
        "4. **Future Learning**: What aspects of POS tagging would you like to explore further? (Neural approaches, custom training, domain adaptation, etc.)\n",
        "\n",
        "5. **Integration**: How does POS tagging fit into larger NLP pipelines? What other NLP tasks might benefit from POS information?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1c5480f",
      "metadata": {
        "id": "b1c5480f"
      },
      "source": [
        "\n",
        "### ✍️ Your Reflection (Write your answers here):\n",
        "**Remember Reflection is not description!**\n",
        "\n",
        "**1. Tool Comparison:**\n",
        "[Your answer here]\n",
        "\n",
        "**2. Real-World Applications:**\n",
        "[Your answer here]\n",
        "\n",
        "**3. Limitations and Solutions:**\n",
        "[Your answer here]\n",
        "\n",
        "**4. Future Learning:**\n",
        "[Your answer here]\n",
        "\n",
        "**5. Integration:**\n",
        "[Your answer here]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e96f81e5",
      "metadata": {
        "id": "e96f81e5"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## 📤 Submission Checklist\n",
        "\n",
        "Before submitting your completed notebook, make sure you have:\n",
        "\n",
        "- [ ] ✅ Completed all TODO sections with working code\n",
        "- [ ] ✅ Answered all reflection questions thoughtfully\n",
        "- [ ] ✅ Created at least one meaningful visualization\n",
        "- [ ] ✅ Tested your code and fixed any errors\n",
        "- [ ] ✅ Added comments explaining your approach\n",
        "- [ ] ✅ Included insights from your analysis\n",
        "\n",
        "### 📋 Submission Instructions:\n",
        "1. **Save your notebook**: File → Save (or Ctrl+S)\n",
        "2. **Download**: File → Download → Download .ipynb\n",
        "3. **Submit**: Upload your completed notebook file to the course management system\n",
        "4. **Filename**: Use format: `L05_LastName_FirstName_ITAI2373.ipynb or pdf`  \n",
        "\n",
        "### 🏆 Grading Criteria:\n",
        "- **Code Completion (40%)**: All exercises completed with working code\n",
        "- **Analysis Quality (30%)**: Thoughtful interpretation of results\n",
        "- **Reflection Depth (20%)**: Insightful answers to reflection questions  \n",
        "- **Code Quality (10%)**: Clean, commented, well-organized code\n",
        "\n",
        "---\n",
        "\n",
        "## 🎉 Great Work!\n",
        "\n",
        "You've successfully explored the fascinating world of POS tagging! You now understand how computers parse human language and can apply these techniques to solve real-world problems.\n",
        "\n",
        "\n",
        "Keep exploring and happy coding! 🚀\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}